from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import re
from typing import Dict, List, Optional

class QuestionRouter:
    """æ··åˆè·¯ç”±å™¨ï¼šè§„åˆ™ + LLM"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        # å…³é”®è¯å­—å…¸
        self.keywords = {
            'fundamental': ['åŸºæœ¬é¢', 'è´¢åŠ¡', 'ä¼°å€¼', 'å¸‚ç›ˆç‡', 'PE', 'å¸‚å‡€ç‡', 'PB', 'ROE', 'è¥æ”¶', 'åˆ©æ¶¦', 'è´Ÿå€º', 'ç°é‡‘æµ'],
            'technical': ['æŠ€æœ¯é¢', 'æŠ€æœ¯æŒ‡æ ‡', 'RSI', 'MACD', 'å‡çº¿', 'MA', 'å¸ƒæ—å¸¦', 'KDJ', 'æˆäº¤é‡', 'è¶‹åŠ¿', 'æ”¯æ’‘', 'é˜»åŠ›'],
            'sentiment': ['æ–°é—»', 'èˆ†æƒ…', 'æƒ…ç»ª', 'æ¶ˆæ¯', 'å¸‚åœºçœ‹æ³•', 'åˆ†æå¸ˆ', 'è¯„çº§', 'çƒ­åº¦'],
            'comparison': ['å¯¹æ¯”', 'æ¯”è¾ƒ', 'æ¨ªå‘', 'vs', 'å“ªä¸ªå¥½', 'å“ªåª', 'é€‰æ‹©']
        }
    
    def _extract_tickers(self, question: str) -> List[str]:
        """æå–è‚¡ç¥¨ä»£ç """
        # åŒ¹é…ç¾è‚¡ä»£ç ï¼ˆ1-5ä¸ªå¤§å†™å­—æ¯ï¼‰
        pattern = r'\b[A-Z]{1,5}\b'
        tickers = re.findall(pattern, question.upper())
        # è¿‡æ»¤å¸¸è§è‹±æ–‡å•è¯
        common_words = {'THE', 'AND', 'OR', 'IS', 'ARE', 'WAS', 'WERE', 'VS', 'PE', 'PB', 'ROE', 'RSI', 'MA', 'KDJ'}
        return [t for t in tickers if t not in common_words]
    
    def _rule_based_routing(self, question: str) -> Optional[Dict]:
        """åŸºäºè§„åˆ™çš„è·¯ç”±"""
        question_lower = question.lower()
        
        # å¯¹æ¯”ä¼˜å…ˆçº§æœ€é«˜
        if any(kw in question_lower for kw in self.keywords['comparison']):
            tickers = self._extract_tickers(question)
            if len(tickers) >= 2:
                return {
                    'agent_type': 'comparison',
                    'tickers': tickers,
                    'confidence': 'high',
                    'method': 'rule'
                }
        
        # ç»Ÿè®¡å…³é”®è¯å‘½ä¸­æ•°
        scores = {}
        for agent_type, keywords in self.keywords.items():
            if agent_type == 'comparison':
                continue
            score = sum(1 for kw in keywords if kw in question_lower)
            if score > 0:
                scores[agent_type] = score
        
        if not scores:
            return None
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„
        best_agent = max(scores.items(), key=lambda x: x[1])
        tickers = self._extract_tickers(question)
        
        return {
            'agent_type': best_agent[0],
            'tickers': tickers,
            'confidence': 'high' if best_agent[1] >= 2 else 'medium',
            'method': 'rule'
        }
    
    def _llm_based_routing(self, question: str) -> Dict:
        """åŸºäº LLM çš„è·¯ç”±ï¼ˆå¤‡ç”¨ï¼‰"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªè‚¡ç¥¨é—®é¢˜åˆ†ç±»ä¸“å®¶ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹é—®é¢˜å±äºå“ªä¸ªç±»åˆ«ï¼š

1. fundamental - åŸºæœ¬é¢åˆ†æï¼ˆè´¢åŠ¡æ•°æ®ã€ä¼°å€¼ã€ç›ˆåˆ©èƒ½åŠ›ï¼‰
2. technical - æŠ€æœ¯é¢åˆ†æï¼ˆæŠ€æœ¯æŒ‡æ ‡ã€è¶‹åŠ¿ã€å›¾è¡¨ï¼‰
3. sentiment - å¸‚åœºæƒ…ç»ªï¼ˆæ–°é—»ã€èˆ†æƒ…ã€åˆ†æå¸ˆçœ‹æ³•ï¼‰
4. comparison - è‚¡ç¥¨å¯¹æ¯”ï¼ˆæ¨ªå‘æ¯”è¾ƒå¤šåªè‚¡ç¥¨ï¼‰

åªè¾“å‡ºç±»åˆ«åç§°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""),
            ("human", "{question}")
        ])
        
        try:
            chain = prompt | self.llm | StrOutputParser()
            result = chain.invoke({"question": question})
            agent_type = result.strip().lower()
            
            # éªŒè¯ç»“æœ
            valid_types = ['fundamental', 'technical', 'sentiment', 'comparison']
            if agent_type not in valid_types:
                agent_type = 'fundamental'  # é»˜è®¤
            
            tickers = self._extract_tickers(question)
            
            return {
                'agent_type': agent_type,
                'tickers': tickers,
                'confidence': 'low',
                'method': 'llm'
            }
        except Exception:
            # LLM å¤±è´¥ï¼Œè¿”å›é»˜è®¤
            return {
                'agent_type': 'fundamental',
                'tickers': self._extract_tickers(question),
                'confidence': 'low',
                'method': 'fallback'
            }
    
    def route(self, question: str) -> Dict:
        """ä¸»è·¯ç”±æ–¹æ³•"""
        # å…ˆå°è¯•è§„åˆ™è·¯ç”±
        result = self._rule_based_routing(question)
        
        # å¦‚æœè§„åˆ™è·¯ç”±å¤±è´¥æˆ–ç½®ä¿¡åº¦ä½ï¼Œä½¿ç”¨ LLM
        if result is None or result['confidence'] == 'low':
            llm_result = self._llm_based_routing(question)
            # å¦‚æœè§„åˆ™æœ‰ç»“æœä½†ç½®ä¿¡åº¦ä½ï¼Œä¼˜å…ˆä½¿ç”¨è§„åˆ™ç»“æœ
            if result is not None:
                return result
            return llm_result
        
        return result
    
    def format_routing_info(self, routing_result: Dict) -> str:
        """æ ¼å¼åŒ–è·¯ç”±ä¿¡æ¯"""
        agent_names = {
            'fundamental': 'åŸºæœ¬é¢åˆ†æ',
            'technical': 'æŠ€æœ¯é¢åˆ†æ',
            'sentiment': 'å¸‚åœºæƒ…ç»ª',
            'comparison': 'è‚¡ç¥¨å¯¹æ¯”'
        }
        
        info = f"ğŸ¯ è·¯ç”±ç»“æœ\n"
        info += f"  â€¢ Agent: {agent_names.get(routing_result['agent_type'], 'æœªçŸ¥')}\n"
        info += f"  â€¢ è‚¡ç¥¨ä»£ç : {', '.join(routing_result.get('tickers', [])) or 'æœªè¯†åˆ«'}\n"
        info += f"  â€¢ ç½®ä¿¡åº¦: {routing_result['confidence']}\n"
        info += f"  â€¢ æ–¹æ³•: {routing_result['method']}\n"
        
        return info
